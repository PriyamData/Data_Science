{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"K3_data.xlsx\", index_col=\"Period\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Sum', 'Big_Small', 'Odd_Even'], dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sum</th>\n",
       "      <th>Big_Small</th>\n",
       "      <th>Odd_Even</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Period</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20240804090727</th>\n",
       "      <td>16</td>\n",
       "      <td>Big</td>\n",
       "      <td>Even</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20240804090726</th>\n",
       "      <td>6</td>\n",
       "      <td>Small</td>\n",
       "      <td>Even</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20240804090725</th>\n",
       "      <td>10</td>\n",
       "      <td>Small</td>\n",
       "      <td>Even</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20240804090724</th>\n",
       "      <td>9</td>\n",
       "      <td>Small</td>\n",
       "      <td>Odd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20240804090723</th>\n",
       "      <td>6</td>\n",
       "      <td>Small</td>\n",
       "      <td>Even</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Sum Big_Small Odd_Even\n",
       "Period                                \n",
       "20240804090727   16       Big     Even\n",
       "20240804090726    6     Small     Even\n",
       "20240804090725   10     Small     Even\n",
       "20240804090724    9     Small      Odd\n",
       "20240804090723    6     Small     Even"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([20240804090727, 20240804090726, 20240804090725, 20240804090724,\n",
       "       20240804090723, 20240804090722, 20240804090721, 20240804090720,\n",
       "       20240804090719, 20240804090718,\n",
       "       ...\n",
       "       20240724090010, 20240724090009, 20240724090008, 20240724090007,\n",
       "       20240724090006, 20240724090005, 20240724090004, 20240724090003,\n",
       "       20240724090002, 20240724090001],\n",
       "      dtype='int64', name='Period', length=16567)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arranging the past results of the look_back period in a row for every result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def create_datasheet(df, look_back=10):\n",
    "    # Initialize the k3_eda DataFrame with required columns\n",
    "    columns = ['Big_small_Result', 'Odd_Even_Result', 'Sum_Result', 'Time', 'Date', 'Day_of_Week']\n",
    "\n",
    "    # Dynamically add look-back columns\n",
    "    for n in range(1, look_back + 1):\n",
    "        columns.extend([f\"Big_small_{n}\", f\"Odd_Even_{n}\", f\"Sum_{n}\"])\n",
    "\n",
    "    # Add columns for counting \"Even\" and \"Big\" occurrences within the look-back period\n",
    "    for n in range(1, look_back + 1):\n",
    "        columns.extend([f\"Even_count_{n}\", f\"Big_count_{n}\"])\n",
    "\n",
    "    k3_eda = pd.DataFrame(columns=columns)\n",
    "\n",
    "    # Populate the k3_eda DataFrame\n",
    "    for i in range(len(df)):\n",
    "        period_str = str(df.index[i])\n",
    "        date_str = period_str[:8]  # Extract YYYYMMDD\n",
    "        time_str = period_str[-4:]  # Extract HHMM\n",
    "\n",
    "        # Convert date_str to a datetime object\n",
    "        date_obj = pd.to_datetime(date_str, format='%Y%m%d')\n",
    "\n",
    "        # Append a new row to k3_eda\n",
    "        new_row = {\n",
    "            'Big_small_Result': df['Big_Small'].iloc[i],\n",
    "            'Odd_Even_Result': df['Odd_Even'].iloc[i],\n",
    "            'Sum_Result': df['Sum'].iloc[i],\n",
    "            'Time': time_str,\n",
    "            'Date': date_obj.strftime('%d'),  # Extract just the day portion\n",
    "            'Day_of_Week': date_obj.day_name()\n",
    "        }\n",
    "\n",
    "        # Add look-back values and count \"Even\" and \"Big\" occurrences\n",
    "        for n in range(1, look_back + 1):\n",
    "            if i + n < len(df):\n",
    "                new_row[f\"Big_small_{n}\"] = df['Big_Small'].iloc[i + n]\n",
    "                new_row[f\"Odd_Even_{n}\"] = df['Odd_Even'].iloc[i + n]\n",
    "                new_row[f\"Sum_{n}\"] = df['Sum'].iloc[i + n]\n",
    "\n",
    "                # Count occurrences within the look-back period\n",
    "                new_row[f\"Even_count_{n}\"] = (df['Odd_Even'].iloc[i+1:i+n+1] == 'Even').sum()\n",
    "                new_row[f\"Big_count_{n}\"] = (df['Big_Small'].iloc[i+1:i+n+1] == 'Big').sum()\n",
    "            else:\n",
    "                new_row[f\"Big_small_{n}\"] = None\n",
    "                new_row[f\"Odd_Even_{n}\"] = None\n",
    "                new_row[f\"Sum_{n}\"] = None\n",
    "                new_row[f\"Even_count_{n}\"] = None\n",
    "                new_row[f\"Big_count_{n}\"] = None\n",
    "\n",
    "        # Convert the new row to DataFrame and concatenate with k3_eda\n",
    "        new_row_df = pd.DataFrame(new_row, index=[0])\n",
    "        k3_eda = pd.concat([k3_eda, new_row_df], ignore_index=True)\n",
    "\n",
    "    return k3_eda\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dummies_column_names(n):\n",
    "    base_columns = ['Odd_Even_Result', 'Day_of_Week']\n",
    "    for i in range(1, n + 1):\n",
    "        base_columns.append(f'Big_small_{i}')\n",
    "        base_columns.append(f'Odd_Even_{i}')\n",
    "    return base_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_drop_column_names(n):\n",
    "    base_columns = ['Odd_Even_Result_Odd']\n",
    "    for i in range(1, n + 1):\n",
    "        base_columns.append(f'Big_small_{i}_Small')\n",
    "        base_columns.append(f'Odd_Even_{i}_Odd')\n",
    "    return base_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "look_back = 30\n",
    "k3_eda = create_datasheet(df, look_back)\n",
    "k3_eda.dropna(inplace=True)\n",
    "# Doing for Odd-even so deleting big-small and sum\n",
    "\n",
    "k3_eda.drop(['Big_small_Result',\"Sum_Result\"],axis=1, inplace= True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies_columns = generate_dummies_column_names(look_back)\n",
    "\n",
    "k3_eda = pd.get_dummies(k3_eda, columns= dummies_columns)\n",
    "\n",
    "drop_columns = generate_drop_column_names(look_back)\n",
    "# 1 means even, 0 means odd. 1 means Big, 0 means small\n",
    "k3_eda.drop(columns= drop_columns, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas.plotting import scatter_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting features and target\n",
    "X = k3_eda.drop(columns=['Odd_Even_Result_Even'])\n",
    "y = k3_eda['Odd_Even_Result_Even']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Time', 'Date', 'Sum_1', 'Sum_2', 'Sum_3', 'Sum_4', 'Sum_5', 'Sum_6',\n",
       "       'Sum_7', 'Sum_8', 'Sum_9', 'Sum_10', 'Even_count_1', 'Big_count_1',\n",
       "       'Even_count_2', 'Big_count_2', 'Even_count_3', 'Big_count_3',\n",
       "       'Even_count_4', 'Big_count_4', 'Even_count_5', 'Big_count_5',\n",
       "       'Even_count_6', 'Big_count_6', 'Even_count_7', 'Big_count_7',\n",
       "       'Even_count_8', 'Big_count_8', 'Even_count_9', 'Big_count_9',\n",
       "       'Even_count_10', 'Big_count_10', 'Day_of_Week_Friday',\n",
       "       'Day_of_Week_Monday', 'Day_of_Week_Saturday', 'Day_of_Week_Sunday',\n",
       "       'Day_of_Week_Thursday', 'Day_of_Week_Tuesday', 'Day_of_Week_Wednesday',\n",
       "       'Big_small_1_Big', 'Odd_Even_1_Even', 'Big_small_2_Big',\n",
       "       'Odd_Even_2_Even', 'Big_small_3_Big', 'Odd_Even_3_Even',\n",
       "       'Big_small_4_Big', 'Odd_Even_4_Even', 'Big_small_5_Big',\n",
       "       'Odd_Even_5_Even', 'Big_small_6_Big', 'Odd_Even_6_Even',\n",
       "       'Big_small_7_Big', 'Odd_Even_7_Even', 'Big_small_8_Big',\n",
       "       'Odd_Even_8_Even', 'Big_small_9_Big', 'Odd_Even_9_Even',\n",
       "       'Big_small_10_Big', 'Odd_Even_10_Even'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['k3_Odd_Even_columns(30).joblib']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = X.columns\n",
    "dump(columns, 'k3_Odd_Even_columns(30).joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['k3_Odd_Even_scaler(30).joblib']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump, load\n",
    "dump(scaler, 'k3_Odd_Even_scaler(30).joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the performance of some popular ML models, from which the best performing ones will be selected for Ensemble method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.499135 (0.017231)\n",
      "\n",
      "LR Model Performance:\n",
      "Confusion Matrix:\n",
      "[[1202 1261]\n",
      " [1214 1288]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.50      0.49      0.49      2463\n",
      "        True       0.51      0.51      0.51      2502\n",
      "\n",
      "    accuracy                           0.50      4965\n",
      "   macro avg       0.50      0.50      0.50      4965\n",
      "weighted avg       0.50      0.50      0.50      4965\n",
      "\n",
      "Accuracy Score: 0.501511\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "LDA: 0.499048 (0.017296)\n",
      "\n",
      "LDA Model Performance:\n",
      "Confusion Matrix:\n",
      "[[1203 1260]\n",
      " [1216 1286]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.50      0.49      0.49      2463\n",
      "        True       0.51      0.51      0.51      2502\n",
      "\n",
      "    accuracy                           0.50      4965\n",
      "   macro avg       0.50      0.50      0.50      4965\n",
      "weighted avg       0.50      0.50      0.50      4965\n",
      "\n",
      "Accuracy Score: 0.501309\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "KNN: 0.502156 (0.014605)\n",
      "\n",
      "KNN Model Performance:\n",
      "Confusion Matrix:\n",
      "[[1236 1227]\n",
      " [1210 1292]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.51      0.50      0.50      2463\n",
      "        True       0.51      0.52      0.51      2502\n",
      "\n",
      "    accuracy                           0.51      4965\n",
      "   macro avg       0.51      0.51      0.51      4965\n",
      "weighted avg       0.51      0.51      0.51      4965\n",
      "\n",
      "Accuracy Score: 0.509164\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "CART: 0.508460 (0.013944)\n",
      "\n",
      "CART Model Performance:\n",
      "Confusion Matrix:\n",
      "[[1253 1210]\n",
      " [1231 1271]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.50      0.51      0.51      2463\n",
      "        True       0.51      0.51      0.51      2502\n",
      "\n",
      "    accuracy                           0.51      4965\n",
      "   macro avg       0.51      0.51      0.51      4965\n",
      "weighted avg       0.51      0.51      0.51      4965\n",
      "\n",
      "Accuracy Score: 0.508359\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "NB: 0.497756 (0.010260)\n",
      "\n",
      "NB Model Performance:\n",
      "Confusion Matrix:\n",
      "[[1164 1299]\n",
      " [1175 1327]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.50      0.47      0.48      2463\n",
      "        True       0.51      0.53      0.52      2502\n",
      "\n",
      "    accuracy                           0.50      4965\n",
      "   macro avg       0.50      0.50      0.50      4965\n",
      "weighted avg       0.50      0.50      0.50      4965\n",
      "\n",
      "Accuracy Score: 0.501712\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "SVM: 0.504749 (0.011243)\n",
      "\n",
      "SVM Model Performance:\n",
      "Confusion Matrix:\n",
      "[[1245 1218]\n",
      " [1230 1272]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.50      0.51      0.50      2463\n",
      "        True       0.51      0.51      0.51      2502\n",
      "\n",
      "    accuracy                           0.51      4965\n",
      "   macro avg       0.51      0.51      0.51      4965\n",
      "weighted avg       0.51      0.51      0.51      4965\n",
      "\n",
      "Accuracy Score: 0.506949\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "# Define your models\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression()))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVM', SVC()))\n",
    "\n",
    "\n",
    "# Evaluate each model in turn and display detailed performance\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    kfold = KFold(n_splits=10)\n",
    "    cv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring='accuracy')\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    \n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)\n",
    "    \n",
    "    # Train the model on the training set\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on the test set\n",
    "    predictions = model.predict(X_test)\n",
    "    \n",
    "    # Display detailed performance metrics\n",
    "    print(f\"\\n{name} Model Performance:\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, predictions))\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, predictions))\n",
    "    print(\"Accuracy Score: %f\" % accuracy_score(y_test, predictions))\n",
    "    print(\"\\n\" + \"-\"*60 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression, Linear Discriminant analysis and KNN has been observed to produce the best result, hence these 3 have been selected for ensemble method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Model Accuracy: 0.51\n",
      "Logistic Regression Accuracy: 0.51\n",
      "LDA Accuracy: 0.51\n",
      "KNN Accuracy: 0.51\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "\n",
    "#  Initialize the individual models\n",
    "lr = LogisticRegression()    #max_iter=200\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "knn = KNeighborsClassifier()    #n_neighbors=5\n",
    "\n",
    "# Create an ensemble model using VotingClassifier\n",
    "ensemble_model = VotingClassifier(estimators=[\n",
    "    ('lr', lr),\n",
    "    ('lda', lda),\n",
    "    ('knn', knn)\n",
    "], voting='hard')\n",
    "\n",
    "# Train the ensemble model\n",
    "ensemble_model.fit(X_train, y_train)\n",
    "\n",
    "#  Make predictions on the test set\n",
    "y_pred = ensemble_model.predict(X_test)\n",
    "\n",
    "#  Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Ensemble Model Accuracy: {accuracy:.2f}')\n",
    "\n",
    "#  Evaluate individual models\n",
    "lr.fit(X_train, y_train)\n",
    "lda.fit(X_train, y_train)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "lr_pred = lr.predict(X_test)\n",
    "lda_pred = lda.predict(X_test)\n",
    "knn_pred = knn.predict(X_test)\n",
    "\n",
    "print(f'Logistic Regression Accuracy: {accuracy_score(y_test, lr_pred):.2f}')\n",
    "print(f'LDA Accuracy: {accuracy_score(y_test, lda_pred):.2f}')\n",
    "print(f'KNN Accuracy: {accuracy_score(y_test, knn_pred):.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['k3_Odd_Even_ensemble_model(30).joblib']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump, load\n",
    "\n",
    "# Save the trained model to a file\n",
    "dump(ensemble_model, 'k3_Odd_Even_ensemble_model(30).joblib')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the performance of LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\priya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\priya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:From c:\\Users\\priya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\priya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "11589/11589 [==============================] - 105s 9ms/step - loss: 0.6938 - accuracy: 0.4933 - val_loss: 0.6931 - val_accuracy: 0.5062\n",
      "Epoch 2/50\n",
      "11589/11589 [==============================] - 100s 9ms/step - loss: 0.6933 - accuracy: 0.5042 - val_loss: 0.6949 - val_accuracy: 0.4950\n",
      "Epoch 3/50\n",
      "11589/11589 [==============================] - 125s 11ms/step - loss: 0.6933 - accuracy: 0.5025 - val_loss: 0.6932 - val_accuracy: 0.4950\n",
      "Epoch 4/50\n",
      "11589/11589 [==============================] - 158s 14ms/step - loss: 0.6934 - accuracy: 0.4979 - val_loss: 0.6931 - val_accuracy: 0.5048\n",
      "Epoch 5/50\n",
      "11589/11589 [==============================] - 150s 13ms/step - loss: 0.6933 - accuracy: 0.4969 - val_loss: 0.6932 - val_accuracy: 0.4950\n",
      "Epoch 6/50\n",
      "11589/11589 [==============================] - 147s 13ms/step - loss: 0.6932 - accuracy: 0.5016 - val_loss: 0.6934 - val_accuracy: 0.4950\n",
      "Epoch 7/50\n",
      "11589/11589 [==============================] - 123s 11ms/step - loss: 0.6931 - accuracy: 0.5101 - val_loss: 0.6948 - val_accuracy: 0.4950\n",
      "Epoch 8/50\n",
      "11589/11589 [==============================] - 135s 12ms/step - loss: 0.6934 - accuracy: 0.5013 - val_loss: 0.6934 - val_accuracy: 0.4950\n",
      "Epoch 9/50\n",
      "11589/11589 [==============================] - 117s 10ms/step - loss: 0.6933 - accuracy: 0.4994 - val_loss: 0.6930 - val_accuracy: 0.5048\n",
      "Epoch 10/50\n",
      "11589/11589 [==============================] - 122s 10ms/step - loss: 0.6932 - accuracy: 0.5011 - val_loss: 0.6935 - val_accuracy: 0.4950\n",
      "Epoch 11/50\n",
      "11589/11589 [==============================] - 126s 11ms/step - loss: 0.6933 - accuracy: 0.5036 - val_loss: 0.6931 - val_accuracy: 0.5020\n",
      "Epoch 12/50\n",
      "11589/11589 [==============================] - 133s 11ms/step - loss: 0.6932 - accuracy: 0.5057 - val_loss: 0.6928 - val_accuracy: 0.5117\n",
      "Epoch 13/50\n",
      "11589/11589 [==============================] - 147s 13ms/step - loss: 0.6932 - accuracy: 0.5060 - val_loss: 0.6928 - val_accuracy: 0.5097\n",
      "Epoch 14/50\n",
      "11589/11589 [==============================] - 147s 13ms/step - loss: 0.6933 - accuracy: 0.5040 - val_loss: 0.6929 - val_accuracy: 0.5123\n",
      "Epoch 15/50\n",
      "11589/11589 [==============================] - 145s 13ms/step - loss: 0.6933 - accuracy: 0.5015 - val_loss: 0.6930 - val_accuracy: 0.5074\n",
      "Epoch 16/50\n",
      "11589/11589 [==============================] - 142s 12ms/step - loss: 0.6932 - accuracy: 0.5011 - val_loss: 0.6939 - val_accuracy: 0.4950\n",
      "Epoch 17/50\n",
      "11589/11589 [==============================] - 141s 12ms/step - loss: 0.6933 - accuracy: 0.5058 - val_loss: 0.6936 - val_accuracy: 0.4940\n",
      "Epoch 18/50\n",
      "11589/11589 [==============================] - 180s 15ms/step - loss: 0.6932 - accuracy: 0.5063 - val_loss: 0.6938 - val_accuracy: 0.4950\n",
      "Epoch 19/50\n",
      "11589/11589 [==============================] - 142s 12ms/step - loss: 0.6932 - accuracy: 0.5025 - val_loss: 0.6934 - val_accuracy: 0.4954\n",
      "Epoch 20/50\n",
      "11589/11589 [==============================] - 164s 14ms/step - loss: 0.6933 - accuracy: 0.5077 - val_loss: 0.6930 - val_accuracy: 0.5072\n",
      "Epoch 21/50\n",
      "11589/11589 [==============================] - 143s 12ms/step - loss: 0.6933 - accuracy: 0.5029 - val_loss: 0.6934 - val_accuracy: 0.4950\n",
      "Epoch 22/50\n",
      "11589/11589 [==============================] - 133s 11ms/step - loss: 0.6933 - accuracy: 0.5042 - val_loss: 0.6931 - val_accuracy: 0.5026\n",
      "Epoch 23/50\n",
      "11589/11589 [==============================] - 136s 12ms/step - loss: 0.6933 - accuracy: 0.5040 - val_loss: 0.6932 - val_accuracy: 0.5024\n",
      "Epoch 24/50\n",
      "11589/11589 [==============================] - 126s 11ms/step - loss: 0.6932 - accuracy: 0.5055 - val_loss: 0.6934 - val_accuracy: 0.4990\n",
      "Epoch 25/50\n",
      "11589/11589 [==============================] - 133s 11ms/step - loss: 0.6932 - accuracy: 0.5043 - val_loss: 0.6929 - val_accuracy: 0.5105\n",
      "Epoch 26/50\n",
      "11589/11589 [==============================] - 139s 12ms/step - loss: 0.6932 - accuracy: 0.5097 - val_loss: 0.6929 - val_accuracy: 0.5119\n",
      "Epoch 27/50\n",
      "11589/11589 [==============================] - 138s 12ms/step - loss: 0.6932 - accuracy: 0.5075 - val_loss: 0.6929 - val_accuracy: 0.5101\n",
      "Epoch 28/50\n",
      "11589/11589 [==============================] - 127s 11ms/step - loss: 0.6932 - accuracy: 0.5047 - val_loss: 0.6929 - val_accuracy: 0.5125\n",
      "Epoch 29/50\n",
      "11589/11589 [==============================] - 111s 10ms/step - loss: 0.6934 - accuracy: 0.5086 - val_loss: 0.6930 - val_accuracy: 0.5105\n",
      "Epoch 30/50\n",
      "11589/11589 [==============================] - 110s 10ms/step - loss: 0.6931 - accuracy: 0.5107 - val_loss: 0.6931 - val_accuracy: 0.5036\n",
      "Epoch 31/50\n",
      "11589/11589 [==============================] - 112s 10ms/step - loss: 0.6932 - accuracy: 0.5077 - val_loss: 0.6931 - val_accuracy: 0.5062\n",
      "Epoch 32/50\n",
      "11589/11589 [==============================] - 124s 11ms/step - loss: 0.6932 - accuracy: 0.5047 - val_loss: 0.6930 - val_accuracy: 0.5119\n",
      "Epoch 33/50\n",
      "11589/11589 [==============================] - 95s 8ms/step - loss: 0.6986 - accuracy: 0.5064 - val_loss: 0.6931 - val_accuracy: 0.5044\n",
      "Epoch 34/50\n",
      "11589/11589 [==============================] - 119s 10ms/step - loss: 0.6932 - accuracy: 0.5068 - val_loss: 0.6931 - val_accuracy: 0.5018\n",
      "Epoch 35/50\n",
      "11589/11589 [==============================] - 102s 9ms/step - loss: 0.6933 - accuracy: 0.5044 - val_loss: 0.6932 - val_accuracy: 0.5060\n",
      "Epoch 36/50\n",
      "11589/11589 [==============================] - 118s 10ms/step - loss: 0.6933 - accuracy: 0.5015 - val_loss: 0.6931 - val_accuracy: 0.5010\n",
      "Epoch 37/50\n",
      "11589/11589 [==============================] - 127s 11ms/step - loss: 0.6934 - accuracy: 0.5060 - val_loss: 0.6932 - val_accuracy: 0.5020\n",
      "Epoch 38/50\n",
      "11589/11589 [==============================] - 124s 11ms/step - loss: 0.6933 - accuracy: 0.5049 - val_loss: 0.6931 - val_accuracy: 0.5028\n",
      "Epoch 39/50\n",
      "11589/11589 [==============================] - 155s 13ms/step - loss: 0.6931 - accuracy: 0.5054 - val_loss: 0.6938 - val_accuracy: 0.4952\n",
      "Epoch 40/50\n",
      "11589/11589 [==============================] - 165s 14ms/step - loss: 0.6932 - accuracy: 0.5082 - val_loss: 0.6930 - val_accuracy: 0.5127\n",
      "Epoch 41/50\n",
      "11589/11589 [==============================] - 152s 13ms/step - loss: 0.6933 - accuracy: 0.5074 - val_loss: 0.6930 - val_accuracy: 0.5054\n",
      "Epoch 42/50\n",
      "11589/11589 [==============================] - 149s 13ms/step - loss: 0.6933 - accuracy: 0.5063 - val_loss: 0.6932 - val_accuracy: 0.5016\n",
      "Epoch 43/50\n",
      "11589/11589 [==============================] - 151s 13ms/step - loss: 0.6932 - accuracy: 0.4952 - val_loss: 0.6934 - val_accuracy: 0.4986\n",
      "Epoch 44/50\n",
      "11589/11589 [==============================] - 156s 13ms/step - loss: 0.6931 - accuracy: 0.5053 - val_loss: 0.6941 - val_accuracy: 0.4946\n",
      "Epoch 45/50\n",
      "11589/11589 [==============================] - 180s 16ms/step - loss: 0.6943 - accuracy: 0.5103 - val_loss: 0.6932 - val_accuracy: 0.5123\n",
      "Epoch 46/50\n",
      "11589/11589 [==============================] - 157s 14ms/step - loss: 0.6931 - accuracy: 0.5094 - val_loss: 0.6931 - val_accuracy: 0.5083\n",
      "Epoch 47/50\n",
      "11589/11589 [==============================] - 135s 12ms/step - loss: 0.6932 - accuracy: 0.5076 - val_loss: 0.6935 - val_accuracy: 0.4936\n",
      "Epoch 48/50\n",
      "11589/11589 [==============================] - 134s 12ms/step - loss: 0.6931 - accuracy: 0.5053 - val_loss: 0.6935 - val_accuracy: 0.5091\n",
      "Epoch 49/50\n",
      "11589/11589 [==============================] - 133s 11ms/step - loss: 0.6931 - accuracy: 0.5038 - val_loss: 0.6933 - val_accuracy: 0.4974\n",
      "Epoch 50/50\n",
      "11589/11589 [==============================] - 133s 11ms/step - loss: 0.6933 - accuracy: 0.5060 - val_loss: 0.6930 - val_accuracy: 0.5085\n",
      "Model Accuracy: 50.85%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "# Build the LSTM model\n",
    "def build_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50, input_shape=input_shape, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Train the model\n",
    "def train_model(model, X_train, y_train, X_test, y_test, epochs=50, batch_size=1):\n",
    "    history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_test, y_test))\n",
    "    return history\n",
    "\n",
    "# Evaluate the model\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(f\"Model Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "\n",
    "# Build and train the model\n",
    "model = build_model((X_train.shape[1], 1))\n",
    "history = train_model(model, X_train, y_train, X_test, y_test)\n",
    "\n",
    "# Evaluate the model\n",
    "evaluate_model(model, X_test, y_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Verdict\n",
    "\n",
    "An accuracy of around 51% has been achieved using the ensemble method, and 50.85% using LSTM. However, proceeding with only 1% edge is not advisable as the Risk:Reward ratio is only 1:1. Also, it can be said that the Casino results are boderline random and gamblers claiming to be able to predict the pattern are victim of Gambler's fallacy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
